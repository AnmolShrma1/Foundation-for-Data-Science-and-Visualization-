{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Nov on Logistic regression Continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a88b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) (predicted probabilities): [0.5 0.5 0.5 0.5]\n",
      "Gradient df/dB_j for each coefficient: [ 0.    -0.5   -0.625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data (input features and labels)\n",
    "X = np.array([\n",
    "    [2, 2],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "])\n",
    "y = np.array([0, 0, 1, 1])  # Assume binary labels for logistic regression\n",
    "\n",
    "# Initialize parameters (coefficients)\n",
    "B = np.zeros(X.shape[1] + 1)  # [B0, B1, B2]\n",
    "\n",
    "# Sigmoid function renamed to h_x\n",
    "def h_x(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Logistic regression model to calculate h(x) once\n",
    "def calculate_h_x(X, B):\n",
    "    # Add intercept\n",
    "    X_intercept = np.c_[np.ones(X.shape[0]), X]  # Adding a column of ones for B0\n",
    "    return h_x(np.dot(X_intercept, B))\n",
    "\n",
    "# Function to calculate the gradient using precomputed h(x)\n",
    "def calculate_gradient(X, y, B, y_pred):\n",
    "    m = X.shape[0]\n",
    "    X_intercept = np.c_[np.ones(X.shape[0]), X]  # Adding intercept term\n",
    "    \n",
    "    # Calculate the gradient using precomputed y_pred (h(x))\n",
    "    gradient = np.dot(X_intercept.T, (y_pred - y)) / m\n",
    "    return gradient\n",
    "\n",
    "# Calculate h(x) once and store it\n",
    "y_pred = calculate_h_x(X, B)\n",
    "print(\"h(x) (predicted probabilities):\", y_pred)\n",
    "\n",
    "# Calculate and print the gradient using stored h(x)\n",
    "gradient = calculate_gradient(X, y, B, y_pred)\n",
    "print(\"Gradient df/dB_j for each coefficient:\", gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbbbee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h(x) (predicted probabilities): [0.5 0.5 0.5 0.5]\n",
      "Gradient df/dB_j for each coefficient: [ 0.    -0.5   -0.625]\n",
      "Predicted Class Labels: [1 1 1 1]\n",
      "Confusion Matrix:\n",
      "TP: 2, TN: 0, FP: 2, FN: 0\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data (input features and labels)\n",
    "X = np.array([\n",
    "    [2, 2],\n",
    "    [3, 4],\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "])\n",
    "y = np.array([0, 0, 1, 1])  # Actual labels\n",
    "\n",
    "# Initialize parameters (coefficients)\n",
    "B = np.zeros(X.shape[1] + 1)  # [B0, B1, B2]\n",
    "\n",
    "# Learning rate (alpha)\n",
    "alpha = 0.01\n",
    "\n",
    "# Sigmoid function renamed to h_x\n",
    "def h_x(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Logistic regression model to calculate h(x) once\n",
    "def calculate_h_x(X, B):\n",
    "    # Add intercept\n",
    "    X_intercept = np.c_[np.ones(X.shape[0]), X]  # Adding a column of ones for B0\n",
    "    return h_x(np.dot(X_intercept, B))\n",
    "\n",
    "# Function to calculate the gradient using precomputed h(x)\n",
    "def calculate_gradient(X, y, B, y_pred):\n",
    "    m = X.shape[0]\n",
    "    X_intercept = np.c_[np.ones(X.shape[0]), X]  # Adding intercept term\n",
    "    # Calculate the gradient using precomputed y_pred (h(x))\n",
    "    gradient = np.dot(X_intercept.T, (y_pred - y)) / m\n",
    "    return gradient\n",
    "\n",
    "# Calculate h(x) (predicted probabilities)\n",
    "y_pred = calculate_h_x(X, B)\n",
    "print(\"h(x) (predicted probabilities):\", y_pred)\n",
    "\n",
    "# Calculate and print the gradient using stored h(x)\n",
    "gradient = calculate_gradient(X, y, B, y_pred)\n",
    "print(\"Gradient df/dB_j for each coefficient:\", gradient)\n",
    "\n",
    "# Generate predicted class labels based on threshold (0.5)\n",
    "y_pred_class = (y_pred >= 0.5).astype(int)\n",
    "print(\"Predicted Class Labels:\", y_pred_class)\n",
    "\n",
    "# Build confusion matrix components\n",
    "TP = np.sum((y_pred_class == 1) & (y == 1))  # True Positives\n",
    "TN = np.sum((y_pred_class == 0) & (y == 0))  # True Negatives\n",
    "FP = np.sum((y_pred_class == 1) & (y == 0))  # False Positives\n",
    "FN = np.sum((y_pred_class == 0) & (y == 1))  # False Negatives\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4233f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
